{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7791ca10232655ac53dd4bba44138d2",
     "grade": false,
     "grade_id": "cell-bf951004994ebba2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition  import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston, load_iris, load_breast_cancer, make_blobs\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cvxpy as cp\n",
    "\n",
    "def grad_check_sparse(f, x, analytic_grad, num_checks=12, h=1e-5, error=1e-9):\n",
    "    \"\"\"\n",
    "    sample a few random elements and only return numerical\n",
    "    in this dimensions\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(num_checks):\n",
    "        ix = tuple([randrange(m) for m in x.shape])\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h  # increment by h\n",
    "        fxph = f(x)  # evaluate f(x + h)\n",
    "        x[ix] = oldval - h  # increment by h\n",
    "        fxmh = f(x)  # evaluate f(x - h)\n",
    "        x[ix] = oldval  # reset\n",
    "\n",
    "        grad_numerical = (fxph - fxmh) / (2 * h)\n",
    "        grad_analytic = analytic_grad[ix]\n",
    "        rel_error = abs(grad_numerical - grad_analytic) / (\n",
    "            abs(grad_numerical) + abs(grad_analytic)\n",
    "        )\n",
    "        print(\n",
    "            \"numerical: %f analytic: %f, relative error: %e\"\n",
    "            % (grad_numerical, grad_analytic, rel_error)\n",
    "        )\n",
    "        assert rel_error < error\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b94485256a5b66d80cbb30860292ac41",
     "grade": false,
     "grade_id": "cell-a61ae6533b88fb95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class PrincipalComponentAnalysis():\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23e107a1a8ddddc51278cf396f27f76f",
     "grade": true,
     "grade_id": "cell-01016aef983d4a70",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-683844a45a94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrincipalComponentAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_centered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mX_model_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_centered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-bc4ec2fa6b93>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_centered = X - np.mean(X, axis=0)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_centered)\n",
    "X_pca_trans = pca.transform(X_centered)\n",
    "\n",
    "model = PrincipalComponentAnalysis(n_components=3)\n",
    "model.fit(X_centered)\n",
    "X_model_trans = model.transform(X_centered)\n",
    "\n",
    "sign_correct_X_model_trans = np.concatenate([np.expand_dims(X_model_trans[:,0],axis=1),-X_model_trans[:,1:]],axis=1)\n",
    "\n",
    "error = rel_error(X_pca_trans, sign_correct_X_model_trans)\n",
    "print(error)\n",
    "assert  error < 1e-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Linear SVM with CVXPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard margin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67a78e61592d16446bae3f77e17ceaea",
     "grade": false,
     "grade_id": "cell-225fb5eb2216ae3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X2, y2 = make_blobs(n_samples=300, centers=2, n_features=12, random_state=47)\n",
    "scaler = StandardScaler()\n",
    "X2 = scaler.fit_transform(X2)\n",
    "y2[y2 == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb10a2e1c603f3c29915c7cac6bf7866",
     "grade": false,
     "grade_id": "cell-b459cc87f3d8726e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$\\min_{\\mathbf{w},b}\\frac{1}{2}||\\mathbf{w}||^2$$ <br>\n",
    "$$\\text{s.t } y_i(\\mathbf{w}^{\\top}\\mathbf{x}_i + b) \\ge 1, \\ i=1...N$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bcc3a988e383b297c2805d1f6aca7dc",
     "grade": false,
     "grade_id": "cell-d04165c70ffbb870",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LinearSVMHardMargin():\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.b = 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # YOUR CODE HERE\n",
    "        self.w = cp.Variable(X.shape[1])\n",
    "        self.b = cp.Variable(1)\n",
    "        cost = cp.norm(self.w, 2)**2/2\n",
    "        constraint = [y@(self.w@X.T + self.b) >= 1]\n",
    "        opt_problem = cp.Problem(cp.Minimize(cost), constraint)\n",
    "        opt_problem.solve()\n",
    "        self.w = self.w.value\n",
    "        self.b = self.b.value\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return the predicted label 1 or -1\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        y = self.w@X.T + self.b\n",
    "        predict_class = np.sign(y)\n",
    "        return predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fcf9bdd4f28f6b42218539a988b638b",
     "grade": true,
     "grade_id": "cell-5d1f0df83bcb86d1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Inequality'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-265-cbacf3ad106f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVMHardMargin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-264-6ece0d0486e7>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mconstraint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mopt_problem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mopt_problem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\Joely\\lib\\site-packages\\cvxpy\\atoms\\affine\\binary_operators.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(lh_exp, rh_exp)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlh_exp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrh_exp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"MulExpression\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;34m\"\"\"Matrix multiplication.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mMulExpression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlh_exp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrh_exp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\Joely\\lib\\site-packages\\cvxpy\\atoms\\affine\\binary_operators.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lh_exp, rh_exp)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlh_exp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrh_exp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBinaryOperator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlh_exp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrh_exp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\Joely\\lib\\site-packages\\cvxpy\\atoms\\atom.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     43\u001b[0m             )\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# Convert raw values to Constants.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mAtom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_to_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_from_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\Joely\\lib\\site-packages\\cvxpy\\atoms\\atom.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m             )\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# Convert raw values to Constants.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mAtom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_to_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_from_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\Joely\\lib\\site-packages\\cvxpy\\expressions\\expression.py\u001b[0m in \u001b[0;36mcast_to_const\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m    468\u001b[0m                         \u001b[1;34m\"Combine Expressions using atoms such as bmat, hstack, and vstack.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m                     )\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mexpr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExpression\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcvxtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\Joely\\lib\\site-packages\\cvxpy\\expressions\\constants\\constant.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_INTF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconst_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_imag\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\Joely\\lib\\site-packages\\cvxpy\\interface\\numpy_interface\\ndarray_interface.py\u001b[0m in \u001b[0;36mconst_to_matrix\u001b[1;34m(self, value, convert_scalars)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Return an identity matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Inequality'"
     ]
    }
   ],
   "source": [
    "model = LinearSVMHardMargin()\n",
    "model.fit(X2, y2)\n",
    "pred = model.predict(X2)\n",
    "accuracy = accuracy_score(y2, pred)\n",
    "print(accuracy)\n",
    "assert accuracy == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14637e9c774165ae0c123891964870b3",
     "grade": false,
     "grade_id": "cell-e1ffa5b41b5d9d99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data3 = load_breast_cancer()\n",
    "X3, y3 = data3.data, data3.target\n",
    "scaler = StandardScaler()\n",
    "X3 = scaler.fit_transform(X3)\n",
    "y3[y3 == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\mathbf{w},b) = \\frac{1}{N} \\sum_{i=1}^N \\max(0, 1- y_i(\\mathbf{w}^{\\top}\\mathbf{x}_i + b)) + \\lambda||\\mathbf{w}||^2_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6723ed1e25d3de291f7156530cf97613",
     "grade": false,
     "grade_id": "cell-dff3e00a210cd783",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LinearSVMSoftMargin():\n",
    "    def __init__(self, alpha=0):\n",
    "        self.w = None\n",
    "        self.b = 0\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # YOUR CODE HERE\n",
    "        self.w = cp.Variable(X.shape[1])\n",
    "        self.b = cp.Variable(1)\n",
    "        obj_func = cp.sum(cp.maximum(0, 1 - cp.multiply(y, self.w@X.T + self.b)))/X.shape[0] + self.alpha * (cp.norm(self.w, 2)**2)\n",
    "        problem = cp.Problem(cp.Minimize(obj_func))\n",
    "        problem.solve()\n",
    "        self.w = self.w.value\n",
    "        self.b = self.b.value\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return the predicted label 1 or -1\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        y = self.w@X.T\n",
    "        predict_class = np.sign(y)\n",
    "        return predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c58313a6f325f89e25254d2bc3aecae",
     "grade": true,
     "grade_id": "cell-915364d1b5f54b7e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9876977152899824\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVMSoftMargin(alpha=1e-3)\n",
    "model.fit(X3, y3)\n",
    "pred = model.predict(X3)\n",
    "accuracy = accuracy_score(y3, pred)\n",
    "print(accuracy)\n",
    "assert accuracy >= 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\mathbf{W}) = \\sum_{i=1}^N \\sum_{j \\neq y_i} \\max(0, s_j - s_{y_i} + 1) + \\lambda||\\mathbf{w}||^2_2$$ <br>\n",
    "$$\\text{where } s_j = (f(\\mathbf{x}_i;\\mathbf{W}))_j = (\\mathbf{W}\\mathbf{x}_i)_j \\text{ is the score for the j-th class}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12b5f742a05bdaf1b6adf2bb6083dcd3",
     "grade": false,
     "grade_id": "cell-67c81d664d204471",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(X.shape[1], 3) * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53138b3da2e0d48438be8ea853f14eca",
     "grade": false,
     "grade_id": "cell-a015ff237ad977a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def svm_loss_naive(W, X, y, alpha):\n",
    "    \"\"\"\n",
    "    Multiclass SVM loss function WITH FOR LOOPS\n",
    "\n",
    "    Inputs:\n",
    "    - W: array of shape (D, C) containing weights\n",
    "    - X: array of shape (N, D) containing a minibatch of data\n",
    "    - y: array of shape (N,) containing training labels\n",
    "    - alpha: (float) regularization \n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W;  same shape as W\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialization\n",
    "    loss = 0.0\n",
    "    dW = np.zeros_like(W)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in range(X.shape[0]):\n",
    "        s_y_i = W.T[y[i]] @ X[i]\n",
    "        for j in range(W.shape[1]):\n",
    "            if j != y[i]:\n",
    "                #Loss calcul\n",
    "            \n",
    "                if W.T[j]@X[i] - s_y_i + 1 > 0:\n",
    "                    loss = loss + W.T[j]@X[i] - s_y_i + 1\n",
    "                    #Diferentiate through y_i (resepct to w[y_i])\n",
    "                    dW[:, y[i]] -= X[i, :]\n",
    "                    #Differentiate through j (respect to w[j])\n",
    "                    dW[:, j] += X[i, :]\n",
    "                \n",
    "    loss = loss + alpha * np.sum(W * W)\n",
    "    dW = dW + 2 * alpha * W\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ca0a0a01822fa2a097921b9df2b6c5",
     "grade": true,
     "grade_id": "cell-94feff1af9a3c069",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -19.000000 analytic: -19.000000, relative error: 1.587074e-10\n",
      "numerical: 43.100000 analytic: 43.100000, relative error: 2.352284e-11\n",
      "numerical: -124.000000 analytic: -124.000000, relative error: 4.757983e-11\n",
      "numerical: -19.000000 analytic: -19.000000, relative error: 1.587074e-10\n",
      "numerical: -75.300000 analytic: -75.300000, relative error: 1.680533e-11\n",
      "numerical: -269.100000 analytic: -269.100000, relative error: 3.193307e-11\n",
      "numerical: -269.100000 analytic: -269.100000, relative error: 3.193307e-11\n",
      "numerical: 143.000000 analytic: 143.000000, relative error: 2.017126e-11\n",
      "numerical: -269.100000 analytic: -269.100000, relative error: 3.193307e-11\n",
      "numerical: 344.400000 analytic: 344.400000, relative error: 2.582216e-13\n",
      "numerical: -13.900000 analytic: -13.900000, relative error: 5.778733e-10\n",
      "numerical: -269.100000 analytic: -269.100000, relative error: 3.193307e-11\n"
     ]
    }
   ],
   "source": [
    "# NO REGLARIZATION\n",
    "loss, dW = svm_loss_naive(W, X, y, 0.0)\n",
    "\n",
    "f = lambda W: svm_loss_naive(W, X, y, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, dW, error=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0df6e08de38631bb7c4d8ce16091899a",
     "grade": true,
     "grade_id": "cell-37dfe1a4bbbdf142",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -18.999536 analytic: -18.999536, relative error: 1.206001e-10\n",
      "numerical: 344.400177 analytic: 344.400177, relative error: 1.315617e-12\n",
      "numerical: -18.999536 analytic: -18.999536, relative error: 1.206001e-10\n",
      "numerical: -111.699974 analytic: -111.699974, relative error: 3.065780e-11\n",
      "numerical: -18.999536 analytic: -18.999536, relative error: 1.206001e-10\n",
      "numerical: 43.099714 analytic: 43.099714, relative error: 3.552638e-11\n",
      "numerical: -13.899609 analytic: -13.899609, relative error: 6.200979e-10\n",
      "numerical: -75.299803 analytic: -75.299803, relative error: 1.787383e-11\n",
      "numerical: 12.500197 analytic: 12.500197, relative error: 4.720953e-10\n",
      "numerical: -75.299803 analytic: -75.299803, relative error: 1.787383e-11\n",
      "numerical: 12.500197 analytic: 12.500197, relative error: 4.720953e-10\n",
      "numerical: -111.699974 analytic: -111.699974, relative error: 3.065780e-11\n"
     ]
    }
   ],
   "source": [
    "#REGLARIZATION\n",
    "loss, dW = svm_loss_naive(W, X, y, 2)\n",
    "\n",
    "f = lambda W: svm_loss_naive(W, X, y, 2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, dW, error=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5ebb303976d8369a9bb802d3976cad1",
     "grade": false,
     "grade_id": "cell-7e17d2c0c1de2480",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def svm_loss_vectorized(W, X, y, alpha):\n",
    "    \"\"\"\n",
    "    Multiclass SVM loss function WITHOUT FOR LOOPS\n",
    "\n",
    "    Inputs:\n",
    "    - W: array of shape (D, C) containing weights\n",
    "    - X: array of shape (N, D) containing a minibatch of data\n",
    "    - y: array of shape (N,) containing training labels\n",
    "    - alpha: (float) regularization \n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W;  same shape as W\n",
    "    \"\"\"\n",
    "    # Initialize the loss and gradient to zero.\n",
    "    loss = 0.0\n",
    "    dW = np.zeros_like(W)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    score_each_classe = X@W\n",
    "    correct_class_score = score_each_classe[np.arange(X.shape[0]), y]\n",
    "    margins = np.maximum(0, (score_each_classe.T - correct_class_score).T + 1)\n",
    "    margins[np.arange(X.shape[0]), y] = 0\n",
    "    loss = np.sum(margins) + alpha*np.sum(W*W)\n",
    "    \n",
    "    X_mask = np.zeros(margins.shape)\n",
    "    X_mask[margins > 0] = 1\n",
    "    count = np.sum(X_mask,axis=1)\n",
    "    X_mask[np.arange(X.shape[0]),y] = -count\n",
    "    dW = X.T.dot(X_mask)\n",
    "    dW = dW\n",
    "    dW += 2*alpha*W\n",
    "    \n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "884d69e79b74e6756f42d7927309de82",
     "grade": true,
     "grade_id": "cell-1bf11ff8259d6847",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 125.600000 analytic: 125.600000, relative error: 4.831012e-12\n",
      "numerical: 143.000000 analytic: 143.000000, relative error: 9.641816e-12\n",
      "numerical: -13.900000 analytic: -13.900000, relative error: 3.553877e-11\n",
      "numerical: -124.000000 analytic: -124.000000, relative error: 2.118254e-11\n",
      "numerical: 43.100000 analytic: 43.100000, relative error: 9.450136e-12\n",
      "numerical: -19.000000 analytic: -19.000000, relative error: 6.567603e-11\n",
      "numerical: -111.700000 analytic: -111.700000, relative error: 2.866153e-12\n",
      "numerical: -55.600000 analytic: -55.600000, relative error: 9.985042e-12\n",
      "numerical: -269.100000 analytic: -269.100000, relative error: 2.475678e-13\n",
      "numerical: -269.100000 analytic: -269.100000, relative error: 2.475678e-13\n",
      "numerical: -55.600000 analytic: -55.600000, relative error: 9.985042e-12\n",
      "numerical: 125.600000 analytic: 125.600000, relative error: 4.831012e-12\n"
     ]
    }
   ],
   "source": [
    "# NO REGLARIZATION\n",
    "loss, dW = svm_loss_vectorized(W, X, y, 0.0)\n",
    "\n",
    "f = lambda W: svm_loss_vectorized(W, X, y, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, dW, error=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53c5c62906c11829422603614eae7ba7",
     "grade": true,
     "grade_id": "cell-33078afde070ae4f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -13.899609 analytic: -13.899609, relative error: 6.668618e-12\n",
      "numerical: 142.999548 analytic: 142.999548, relative error: 5.681478e-12\n",
      "numerical: 142.999548 analytic: 142.999548, relative error: 5.681478e-12\n",
      "numerical: -55.599253 analytic: -55.599253, relative error: 1.393149e-11\n",
      "numerical: -123.999684 analytic: -123.999684, relative error: 2.228772e-11\n",
      "numerical: 344.400177 analytic: 344.400177, relative error: 1.315617e-12\n",
      "numerical: -18.999536 analytic: -18.999536, relative error: 1.037888e-10\n",
      "numerical: -75.299803 analytic: -75.299803, relative error: 9.996692e-13\n",
      "numerical: -18.999536 analytic: -18.999536, relative error: 1.037888e-10\n",
      "numerical: -75.299803 analytic: -75.299803, relative error: 9.996692e-13\n",
      "numerical: 125.600229 analytic: 125.600229, relative error: 1.416218e-12\n",
      "numerical: -75.299803 analytic: -75.299803, relative error: 9.996692e-13\n"
     ]
    }
   ],
   "source": [
    "# REGLARIZATION\n",
    "loss, dW = svm_loss_vectorized(W, X, y, 2)\n",
    "\n",
    "f = lambda W: svm_loss_vectorized(W, X, y, 2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, dW, error=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f1639f76b795c999d467767430e2778",
     "grade": false,
     "grade_id": "cell-41975286849a6d83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LinearModel():\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.W = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "    def train(self, X, y, learning_rate=1e-3, alpha=0, num_iters=100, batch_size=200, verbose=False):\n",
    "        if self.fit_intercept == True:\n",
    "            one = np.array([np.ones(X.shape[0])])\n",
    "            X = np.concatenate((X, one.T), axis=1)\n",
    "            \n",
    "            \n",
    "        N, d = X.shape\n",
    "        \n",
    "        C = (np.max(y) + 1) \n",
    "        if self.W is None: # Initialization\n",
    "            self.W = 0.001 * np.random.randn(d, C)\n",
    "\n",
    "        # Run stochastic gradient descent to optimize W\n",
    "        \n",
    "        loss_history = []\n",
    "        for it in range(num_iters):\n",
    "            X_batch = None\n",
    "            y_batch = None\n",
    "                                                               \n",
    "            # Sample batch_size elements in X_batch and y_batch\n",
    "            # X_batch shape is  (batch_size, d) and y_batch shape is (batch_size,)                                                                                          \n",
    "            # Hint: Use np.random.choice to generate indices\n",
    "            n = len(X)\n",
    "            index = np.random.choice(range(n), size=batch_size)\n",
    "            X_batch = X[index]\n",
    "            y_batch = y[index]\n",
    "            \n",
    "            # evaluate loss and gradient\n",
    "            loss, dW = self.loss(X_batch, y_batch, alpha)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            # perform parameter update                                                                \n",
    "            # Update the weights w using the gradient and the learning rate.          \n",
    "            self.W = self.W - learning_rate * dW\n",
    "            \n",
    "            if verbose and it % 10000 == 0:\n",
    "                print(\"iteration %d / %d: loss %f\" % (it, num_iters, loss))\n",
    "       #print(loss_history)        \n",
    "        return loss_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        pass\n",
    "\n",
    "class LinearSVM(LinearModel):\n",
    "    \"\"\" Softmax regression \"\"\"\n",
    "\n",
    "    def loss(self, X_batch, y_batch, alpha):\n",
    "        return svm_loss_vectorized(self.W, X_batch, y_batch, alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Inputs:\n",
    "        - X: array of shape (N, D) \n",
    "\n",
    "        Returns:\n",
    "        - y_pred: 1-dimensional array of length N, each element is an integer giving the predicted class \n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if self.fit_intercept == True:\n",
    "            one = np.array([np.ones(X.shape[0])])\n",
    "            X = np.concatenate((X, one.T), axis=1)\n",
    "        #print(X.shape)\n",
    "        #print(self.W.shape)\n",
    "        y_pred = np.argmax(X@self.W, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aee08beb636f046b69da3ada47961ae6",
     "grade": true,
     "grade_id": "cell-f1cb5669bcaed283",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 75000: loss 128.168167\n",
      "iteration 10000 / 75000: loss 1.506808\n",
      "iteration 20000 / 75000: loss 3.573936\n",
      "iteration 30000 / 75000: loss 2.615055\n",
      "iteration 40000 / 75000: loss 2.690473\n",
      "iteration 50000 / 75000: loss 1.366776\n",
      "iteration 60000 / 75000: loss 1.683512\n",
      "iteration 70000 / 75000: loss 1.036326\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVM(fit_intercept=True)\n",
    "model.train(X, y, num_iters=75000, batch_size=64, learning_rate=1e-3, verbose=True)\n",
    "pred = model.predict(X)\n",
    "model_accuracy = accuracy_score(y, pred)\n",
    "print(model_accuracy)\n",
    "assert model_accuracy > 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
