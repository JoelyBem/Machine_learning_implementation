{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT USE FOR LOOP ON number of samples N but ONLY ON number of classes C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5b3a9bb5f9459df46861b5d84bda38",
     "grade": false,
     "grade_id": "cell-f4572dec0c7469a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits, load_digits\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19e957d3826dd3977f54f428a8744d6",
     "grade": false,
     "grade_id": "cell-d82471ddcebf7ede",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X_train, y_train = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5735812b7d43eb37d2bd53c84670597",
     "grade": false,
     "grade_id": "cell-212a715c4b2f4e77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_priors(X, y):\n",
    "    \"\"\"\n",
    "    Prior probability for each class \n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - priors : array of shape (C,)\n",
    "    \"\"\"\n",
    "    C = (np.max(y) + 1)\n",
    "    priors = np.zeros(C)\n",
    "    # YOUR CODE HERE\n",
    "    for classe in np.unique(y):\n",
    "        priors[classe] = len(y[y == classe])/len(y)\n",
    "    \n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4595f1d0682daf1d642222e34ca7546f",
     "grade": true,
     "grade_id": "cell-25707d195d3be37b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "priors = compute_priors(X_train, y_train)\n",
    "error = rel_error(sk_model.priors_, priors)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 3]\n",
      " [2 1 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.5, 1. , 3. ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 1, 3], [2, 1, 3]])\n",
    "print(a)\n",
    "np.mean(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80987a776d96e04af5c7a0922be6fc7b",
     "grade": false,
     "grade_id": "cell-a4f5a8d209b51a14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_means(X, y):\n",
    "    \"\"\"\n",
    "    Mean estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - means : array of shape (C, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    means = np.zeros((C, D))\n",
    "    # YOUR CODE HERE\n",
    "    for classe in np.unique(y):\n",
    "        idx_classe = np.where(y == classe)\n",
    "        X_classe = X[idx_classe]\n",
    "        means[classe, :] = np.mean(X_classe, axis=0)\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5139bd849307229ab94c6dc869516b",
     "grade": true,
     "grade_id": "cell-1ea0c5a7199f1d21",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "means = compute_means(X_train, y_train)\n",
    "error = rel_error(sk_model.means_, means)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance formulas:\n",
    "$$ Cov_{x, y} = \\dfrac{\\sum_{i=1}^{N}(x_i - \\bar{x})(y_i - \\bar{y})}{N-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 6.],\n",
       "       [1., 2., 6.],\n",
       "       [1., 2., 6.],\n",
       "       [1., 2., 6.],\n",
       "       [1., 2., 6.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((5, 3)) * np.array([1, 2, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d440cdafa2d4b166c5220793a35fcf7",
     "grade": false,
     "grade_id": "cell-f1401a628db797ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigmas_gda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariances : array of shape (C, D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariances = np.zeros((C, D, D))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for classe in np.unique(y):\n",
    "        idx_classe = np.where(y == classe)\n",
    "        X_classe = X[idx_classe]\n",
    "        len_classe = len(X_classe)\n",
    "        covariances[classe] = ((X_classe - np.ones((len_classe, D))* means[classe]).T @ (X_classe - np.ones((len_classe, D)) * means[classe]))/(len_classe - 1)\n",
    "    \n",
    "    return covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a27ecc6bbc72e72cfebaffd3ede565",
     "grade": true,
     "grade_id": "cell-6b136fdb522b6eff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.105265823471216e-16\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigmas_gda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "824613ff0ad0e3acb8e67b499598fbba",
     "grade": false,
     "grade_id": "cell-9970ad744b99041a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigma_lda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for LDA, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariance : array of shape (D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariance = np.zeros((D, D))\n",
    "    # YOUR CODE HERE\n",
    "    for classe in np.unique(y):\n",
    "        idx_classe = np.where(y == classe)\n",
    "        X_classe = X[idx_classe]\n",
    "        len_classe = len(X_classe)\n",
    "        covariance += ((X_classe - np.ones((len_classe, D))* means[classe]).T @ (X_classe - np.ones((len_classe, D)) * means[classe]))\n",
    "    covariance = covariance/N\n",
    "    \n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a95472e963297e49709fc0b8c212e341",
     "grade": true,
     "grade_id": "cell-686b35c7c584416e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.058735273151232e-16\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigma_lda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b0c0ed8697c9ae414131f3918c0037",
     "grade": false,
     "grade_id": "cell-17c0ce2515e2fc7c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_lda(X, C, priors, means, covariance):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariance : array of shape (D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    W = np.zeros((C,D))\n",
    "    b = np.zeros(C)\n",
    "    # YOUR CODE HERE\n",
    "    for classe in range(C):\n",
    "        cov_inv = np.linalg.inv(covariance)\n",
    "        W[classe] = cov_inv@means[classe]\n",
    "        b[classe] = np.log(priors[classe]) - means[classe].T@cov_inv@means[classe]/2\n",
    "        \n",
    "    b_matrix = np.ones([N, C]) * b\n",
    "    log_posterior = X@W.T + b_matrix\n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bb8777a126866cace4cb4d1b73225f5",
     "grade": false,
     "grade_id": "cell-7a43326dd032e8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NO TEST FOR LOG-POSTERIOR LDA. Mitambatra eo ambany ny test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2ed41a12624f40c8eabd8a1bac44cb4",
     "grade": false,
     "grade_id": "cell-cc5e3a7eddeb02ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_gda(X, C, priors, means, covariances):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariances : array of shape (C, D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    # YOUR CODE HERE\n",
    "    for classe in range(C):\n",
    "        means_classe = means[classe]\n",
    "        prior_classe = priors[classe]\n",
    "        covariance_classe = covariances[classe]\n",
    "        log_posterior[:, classe] = np.log(prior_classe) - np.log(np.linalg.det(covariance_classe))/2 - np.diag((X - means_classe)@np.linalg.inv(covariance_classe)@(X - means_classe).T)/2\n",
    "        \n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c0afab4af1700e0a0fc48dd1118bdd",
     "grade": true,
     "grade_id": "cell-d58bf74c60153098",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.654253389730232e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "C = (np.max(y_train) + 1)\n",
    "log_posterior = compute_log_posterior_gda(X_train, C, sk_model.priors_, sk_model.means_, sk_model.covariance_)\n",
    "error = rel_error(np.asarray(sk_model._decision_function(X_train)), log_posterior)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea4a371e372fa034dcbf73d579c3358",
     "grade": false,
     "grade_id": "cell-f5cbad4c325e856e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbClassifier():\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        # YOUR CODE HERE\n",
    "        y_classe = np.argmax(log_post, axis=1)\n",
    "        return y_classe\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        # YOUR CODE HERE\n",
    "        proba = np.exp(log_post)/np.sum(np.exp(log_post), axis=1).reshape((-1, 1))\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c234be9d70fd14a4551b6fcbf8de7ea5",
     "grade": false,
     "grade_id": "cell-1bbbe43fcaed8c4e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigma_lda(X, y, self.means)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        log_posterior = compute_log_posterior_lda(X, C, self.priors, self.means, self.cov)\n",
    "        return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "470a4776ad0f7dd0fa6df62af2985724",
     "grade": true,
     "grade_id": "cell-103960c9425d1e47",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "pred = lda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c02ef4c722a12c047cdd79a33b701bf",
     "grade": false,
     "grade_id": "cell-a86acf06e6c80728",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class QDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigmas_gda(X, y, self.means)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        log_posterior = compute_log_posterior_gda(X, C, self.priors, self.means, self.cov)\n",
    "        return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e49782d08f05716006eaa10b9483f",
     "grade": true,
     "grade_id": "cell-407cb9988a114256",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7666654f5e7cfcd44a8c2dc0291c0ed9",
     "grade": true,
     "grade_id": "cell-1d95b01b2541d240",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6651042200099916e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict_proba(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict_proba(X_train)\n",
    "\n",
    "error = rel_error(pred, sk_pred)\n",
    "print(error)\n",
    "assert error < 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bernouilli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X_train2, y_train2 = data.data, data.target\n",
    "X_train2_transf = Binarizer().fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70742cc3e580d8bfdbf0b9de07a87912",
     "grade": false,
     "grade_id": "cell-d5b51da0e0b8dcc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BernouilliNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.theta = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameter theta\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.theta = np.zeros((D, self.C))\n",
    "        self.priors = np.zeros(self.C)\n",
    "        # YOUR CODE HERE\n",
    "        for classe in range(self.C):\n",
    "            N_c = len(y[y == classe])\n",
    "            self.priors[classe] = N_c/len(y)\n",
    "            X_classe = X[np.where(y==classe)]\n",
    "            self.theta[:, classe] = np.sum(X_classe, axis=0)/N_c\n",
    "            \n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        for classe in range(self.C):\n",
    "            theta_bar = 1 - self.theta[:, classe]\n",
    "            theta_mat = np.ones((N, D)) * self.theta[:, classe]\n",
    "            theta_bar_mat = 1 - theta_mat\n",
    "            X_bar = 1 - X\n",
    "            log_post[:, classe] = np.log(self.priors[classe]) + np.sum(X*np.log(theta_mat + 1e-10) + X_bar * np.log(theta_bar_mat + 1e-10), axis=1)   \n",
    "            \n",
    "        return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa098602d1a9e4c9cdca9cf73180a44",
     "grade": true,
     "grade_id": "cell-f960b1ec2ce34b3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.8636616583194212\n",
      "Your Accuracy :  0.8742348358375069\n"
     ]
    }
   ],
   "source": [
    "sk_model = BernoulliNB()\n",
    "sk_model.fit(X_train2_transf, y_train2)\n",
    "sk_pred = sk_model.predict(X_train2_transf)\n",
    "\n",
    "model = BernouilliNaiveBayes()\n",
    "model.fit(X_train2_transf, y_train2)\n",
    "pred = model.predict(X_train2_transf)\n",
    "\n",
    "sk_acc = accuracy_score(y_train2, sk_pred)\n",
    "model_acc = accuracy_score(y_train2, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d67f1b1383503b5e5203c265f59b99d",
     "grade": false,
     "grade_id": "cell-186f17a680895047",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.mu = None\n",
    "        self.sigma = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameters mu and sigma\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.sigma = np.zeros((D, self.C))\n",
    "        self.mu = np.zeros((D,self.C))\n",
    "        self.priors = np.zeros(self.C)\n",
    "        # YOUR CODE HERE\n",
    "        for classe in range(C):\n",
    "            N_c = len(y[y==classe])\n",
    "            self.priors[classe] = N_c/len(y)\n",
    "            X_classe = X[np.where(y==classe)]\n",
    "            self.mu[:, classe] = np.sum(X_classe, axis=0)/N_c\n",
    "            self.sigma[:, classe] = np.sum(np.square(X_classe - self.mu[:, classe]), axis=0)/N_c\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        for classe in range(self.C):\n",
    "            u_matrice = np.ones((N, D)) * self.mu[:, classe]\n",
    "            sigma_matrice = np.ones((N, D)) * self.sigma[:, classe]\n",
    "            log_post[:, classe] = np.log(self.priors[classe]) + np.sum(np.log((1/np.sqrt(sigma_matrice*2*np.pi)) * np.exp((-0.5)*np.square(X-u_matrice)/sigma_matrice)), axis=1)   \n",
    "            \n",
    "        return log_post\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "print(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d510e4b6069f1d0549606f4a4a12416",
     "grade": true,
     "grade_id": "cell-7ac37952b1e80482",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.96\n",
      "Your Accuracy :  0.96\n"
     ]
    }
   ],
   "source": [
    "sk_model = GaussianNB()\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "model = GaussianNaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_train)\n",
    "\n",
    "sk_acc = accuracy_score(y_train, sk_pred)\n",
    "model_acc = accuracy_score(y_train, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
